{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run in blender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bpy\n",
    "import glob\n",
    "local_path = \"/Users/pataranansethpakdee/Documents/GitHub/\"\n",
    "vrm_filepath = local_path+\"3D-Waifu-Model-Generator/Datasets/3D_VRMModel/\"\n",
    "processed_filepath = local_path + \"3D-Waifu-Model-Generator/Datasets/3D_ProcessedModel/\"\n",
    "image_filepath = local_path + \"3D-Waifu-Model-Generator/Datasets/2D_Image/\"\n",
    "vrm_files = glob.glob(f'{vrm_filepath}*')\n",
    "\n",
    "def purge_orphans():\n",
    "    bpy.ops.outliner.orphans_purge(do_local_ids=True, do_linked_ids=True, do_recursive=True)\n",
    "\n",
    "def clean_scene():\n",
    "    scene = bpy.context.scene\n",
    "    bpy.data.scenes.new(\"Scene\")\n",
    "    bpy.data.scenes.remove(scene, do_unlink=True)\n",
    "    purge_orphans()\n",
    "    \n",
    "def set_new_camera():\n",
    "    scene = bpy.context.scene\n",
    "    cam_data = bpy.data.cameras.new(name=\"Camera\")\n",
    "    cam = bpy.data.objects.new(name=\"Camera\", object_data=cam_data)\n",
    "    scene.collection.objects.link(cam)\n",
    "    scene.camera = cam\n",
    "    cam.location = (0, -5.3, 0.8)\n",
    "    cam.rotation_euler = (1.5708, 0, 0) \n",
    "\n",
    "def new_scene():\n",
    "    clean_scene()\n",
    "    set_new_camera()\n",
    "\n",
    "count = 0\n",
    "\n",
    "for file in vrm_files:\n",
    "    \n",
    "    file_name = str(count).zfill(4)\n",
    "\n",
    "    clean_scene()\n",
    "    set_new_camera()\n",
    "    bpy.ops.import_scene.vrm(filepath=file)\n",
    "    scene = bpy.context.scene\n",
    "\n",
    "\n",
    "    # Render settings\n",
    "    scene.render.filepath = f'{image_filepath}{file_name}.png'\n",
    "    scene.render.image_settings.file_format = 'PNG'\n",
    "    scene.render.resolution_x = 1920\n",
    "    scene.render.resolution_y = 1080\n",
    "\n",
    "    # Render the image\n",
    "    bpy.ops.render.render(write_still=True)\n",
    "\n",
    "    #bpy.ops.export_scene.gltf(filepath=f\"{processed_filepath}{file_name}.glb\")\n",
    "    bpy.ops.export_scene.gltf(filepath=f\"{processed_filepath}{file_name}.glb\", \n",
    "                         export_format='GLB', \n",
    "                         export_image_format='JPEG',\n",
    "                         export_image_add_webp=True,\n",
    "                         export_image_webp_fallback=True,\n",
    "                         export_texcoords=True,\n",
    "                         export_normals=True,\n",
    "                         export_materials='EXPORT',\n",
    "                         export_vertex_color='MATERIAL',\n",
    "                         export_all_vertex_colors=True)\n",
    "    count+=1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this in Window "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert .ply to point cloud\n",
    "import trimesh\n",
    "import glob , os\n",
    "ply_path = \"Datasets/3D_ProcessedModel\"\n",
    "ply_files = glob.glob(r\"Datasets/3D_ProcessedModel/*\")\n",
    "\n",
    "for file in ply_files:\n",
    "    file_name = (file.split('/')[-1]).split(\".\")[0]\n",
    "    path = f\"{ply_path}/{file_name}.glb\"\n",
    "    scene = trimesh.load(file)\n",
    "\n",
    "    # Traverse all geometries (meshes) in the scene\n",
    "    point_clouds = []\n",
    "    for name, mesh in scene.geometry.items():\n",
    "        vertices = mesh.vertices\n",
    "        colors = mesh.visual.to_color().vertex_colors  # Optional: may be texture-based\n",
    "        \n",
    "        # Sample points from the mesh\n",
    "        num_samples = 5000  # Adjust this number for more points\n",
    "        if len(vertices) > num_samples:\n",
    "            indices = np.random.choice(len(vertices), num_samples, replace=False)\n",
    "            sampled_vertices = vertices[indices]\n",
    "            sampled_colors = colors[indices]\n",
    "        else:\n",
    "            sampled_vertices = vertices\n",
    "            sampled_colors = colors\n",
    "\n",
    "        # Combine vertices and colors into a point cloud\n",
    "        point_cloud_with_color = [(*v, *c[:3]) for v, c in zip(sampled_vertices, sampled_colors)]\n",
    "        point_clouds.append(point_cloud_with_color)\n",
    "    all_points = [point for pc in point_clouds for point in pc]\n",
    "    points = np.array([p[:3] for p in all_points])\n",
    "    colors = np.array([p[3:] for p in all_points]) / 255.0  # Normalize color values\n",
    "\n",
    "    # Create Open3D point cloud\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(points)\n",
    "    pcd.colors = o3d.utility.Vector3dVector(colors)\n",
    "    o3d.io.write_point_cloud(f\"Processed_Data/3D_PointCloud/{file_name}.ply\", pcd)\n",
    "#o3d.io.write_point_cloud(f\"Processed_Data/3D_PointCloud/{file_name}.pts\",pcd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from plyfile import PlyData\n",
    "def load_pointcloud(ply_file):\n",
    "    ply_data = PlyData.read(ply_file)\n",
    "    vertices = np.vstack([ply_data['vertex'].data['x'], \n",
    "                          ply_data['vertex'].data['y'], \n",
    "                          ply_data['vertex'].data['z']]).T\n",
    "    colors = np.vstack([ply_data['vertex'].data['red'], \n",
    "                        ply_data['vertex'].data['green'], \n",
    "                        ply_data['vertex'].data['blue']]).T\n",
    "    return vertices, colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-5.02770916e-02,  9.37048197e-01,  6.82605505e-02],\n",
       "        [-7.08752945e-02,  9.46168542e-01,  8.04238841e-02],\n",
       "        [-2.99292710e-02,  1.61273026e+00, -6.11106046e-02],\n",
       "        ...,\n",
       "        [ 9.65739861e-02,  1.51713276e+00,  1.42953813e-03],\n",
       "        [-1.84429940e-02,  1.53768718e+00,  7.59180263e-02],\n",
       "        [ 4.21817377e-02,  1.60382962e+00,  2.55565792e-02]]),\n",
       " array([[ 51,  48,  51],\n",
       "        [ 54,  54,  52],\n",
       "        [248, 216, 190],\n",
       "        ...,\n",
       "        [165, 130, 133],\n",
       "        [210, 193, 199],\n",
       "        [228, 210, 211]], dtype=uint8))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
